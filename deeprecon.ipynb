{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cbed2da",
   "metadata": {},
   "source": [
    "PyTorch simulation of a Flush+Reload-style reconstruction on VGG16\n",
    "\n",
    "What this does:\n",
    "1) Build VGG16(+Softmax), log a ground-truth op sequence via forward hooks.\n",
    "2) Simulate a probing process over framework ops with realistic durations & noise.\n",
    "3) Denoise (per-function debounce) and parse with a small VGG FSM.\n",
    "4) Report 8 attributes and block structure (convs per block)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9427efb6",
   "metadata": {},
   "source": [
    "This notebook simulates the DeepRecon Flush+Reload attack for architecture extraction on VGG16.\n",
    "\n",
    "## Imports + utility functions (set_seed, count_attrs, etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08aaffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "\n",
    "# ---------- utils ----------\n",
    "def set_seed(s=7):\n",
    "    random.seed(s); np.random.seed(s); torch.manual_seed(s)\n",
    "\n",
    "def count_attrs(seq: List[str]) -> Dict[str,int]:\n",
    "    return {\n",
    "        \"#convs\":   sum(x==\"Conv2D\"   for x in seq),\n",
    "        \"#fcs\":     sum(x==\"FC\"       for x in seq),\n",
    "        \"#softms\":  sum(x==\"Softmax\"  for x in seq),\n",
    "        \"#relus\":   sum(x==\"ReLU\"     for x in seq),\n",
    "        \"#mpools\":  sum(x==\"MaxPool\"  for x in seq),\n",
    "        \"#apools\":  sum(x==\"AvgPool\"  for x in seq),\n",
    "        \"#merges\":  sum(x==\"Merge\"    for x in seq),\n",
    "        \"#biases\":  sum(x==\"BiasAdd\"  for x in seq),\n",
    "    }\n",
    "\n",
    "def split_blocks_no_bias(seq: List[str]) -> List[List[str]]:\n",
    "    \"\"\"Split feature-extractor ops by MaxPool (ignore BiasAdd).\"\"\"\n",
    "    blocks, cur = [], []\n",
    "    for op in seq:\n",
    "        if op == \"BiasAdd\":  # ignore for classic block view\n",
    "            continue\n",
    "        if op == \"MaxPool\":\n",
    "            blocks.append(cur[:]); cur=[]\n",
    "        else:\n",
    "            cur.append(op)\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5decc9",
   "metadata": {},
   "source": [
    "# 1) Build VGG16 and record ground-truth ops\n",
    "\n",
    "Build VGG16WithSoftmax, run one forward, record GT ops. Show the first 30 ops as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16WithSoftmax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "        self.features = base.features\n",
    "        self.avgpool = base.avgpool\n",
    "        self.classifier = base.classifier\n",
    "        self.softmax = nn.Softmax(dim=1)  # explicit Softmax to make it visible\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "def op_name_from_module(m: nn.Module) -> str:\n",
    "    if isinstance(m, nn.Conv2d):      return \"Conv2D\"\n",
    "    if isinstance(m, nn.ReLU):        return \"ReLU\"\n",
    "    if isinstance(m, nn.MaxPool2d):   return \"MaxPool\"\n",
    "    if isinstance(m, nn.AvgPool2d):   return \"AvgPool\"\n",
    "    if isinstance(m, nn.Linear):      return \"FC\"\n",
    "    if isinstance(m, nn.Softmax):     return \"Softmax\"\n",
    "    # treat everything else as None (ignored)\n",
    "    return \"\"\n",
    "\n",
    "def record_ops(model: nn.Module, x: torch.Tensor) -> List[str]:\n",
    "    ops = []\n",
    "    def make_hook(name):\n",
    "        def hook(_m, _inp, _out):\n",
    "            n = op_name_from_module(_m)\n",
    "            if n: ops.append(n)\n",
    "        return hook\n",
    "    handles=[]\n",
    "    for m in model.modules():\n",
    "        if m is model: continue\n",
    "        if op_name_from_module(m):\n",
    "            handles.append(m.register_forward_hook(make_hook(repr(m))))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _ = model(x)\n",
    "    for h in handles: h.remove()\n",
    "    # inject BiasAdd after each Conv/FC (simulating framework bias kernels)\n",
    "    seq = []\n",
    "    for op in ops:\n",
    "        seq.append(op)\n",
    "        if op in (\"Conv2D\",\"FC\"):\n",
    "            seq.append(\"BiasAdd\")\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfe0c78",
   "metadata": {},
   "source": [
    "# 2) Simulate Flush+Reload probes with noise\n",
    "\n",
    "Simulate noisy probe trace (simulate_trace), plot latency histogram (hits vs misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa50748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_trace(gt_seq: List[str],\n",
    "                   durations_us: Dict[str,int],\n",
    "                   probe_interval_us: int = 40,\n",
    "                   hit_prob_active: float = 0.98,\n",
    "                   false_pos_rate: float = 0.002,\n",
    "                   drop_rate: float = 0.01,\n",
    "                   hit_cycles: Tuple[int,int]=(80,120),\n",
    "                   miss_cycles: Tuple[int,int]=(280,360)) -> List[Tuple[int,str,int,int]]:\n",
    "    \"\"\"\n",
    "    Returns list of (timestamp_ns, function, latency_cycles, is_hit)\n",
    "    \"\"\"\n",
    "    # Build schedule (serialized ops)\n",
    "    t = 0\n",
    "    schedule = []\n",
    "    for op in gt_seq:\n",
    "        dur = durations_us.get(op, 120)\n",
    "        schedule.append((op, t, t+dur))\n",
    "        t += dur\n",
    "    total_us = t\n",
    "\n",
    "    monitor = [\"Conv2D\",\"FC\",\"ReLU\",\"MaxPool\",\"AvgPool\",\"Softmax\",\"Merge\",\"BiasAdd\"]\n",
    "    records = []\n",
    "    now = 0\n",
    "    idx = 0\n",
    "    curr = schedule[idx] if idx < len(schedule) else None\n",
    "    while now < total_us + 2000:\n",
    "        # advance current\n",
    "        while curr and now > curr[2]:\n",
    "            idx += 1\n",
    "            curr = schedule[idx] if idx < len(schedule) else None\n",
    "        active = curr[0] if (curr and curr[1] <= now <= curr[2]) else None\n",
    "        for f in monitor:\n",
    "            if f == active:\n",
    "                is_hit = (random.random() >= drop_rate) and (random.random() < hit_prob_active)\n",
    "            else:\n",
    "                is_hit = (random.random() < false_pos_rate)\n",
    "            lat = random.randint(*(hit_cycles if is_hit else miss_cycles))\n",
    "            records.append((int(now*1000), f, lat, int(is_hit)))\n",
    "        now += probe_interval_us\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7351a2e3",
   "metadata": {},
   "source": [
    "# 3) Denoise + FSM parsing\n",
    "\n",
    "Denoise the trace, show number of events before/after\n",
    "FSM parsing (vgg_fsm_parse), show recovered ops\n",
    "\n",
    "the FSM encodes the legal layer order of VGG (e.g., Conv → ReLU → Pool → …).\n",
    "It consumes the noisy sequence of observed ops and only keeps a path that matches this grammar, which recovers the valid architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbfa857",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.9.21)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"/scratch/pournami/architecture_weight_simulation/FR Simulation/.venv/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def denoise(records: List[Tuple[int,str,int,int]],\n",
    "            latency_hit_threshold: int = 180,\n",
    "            per_func_debounce_ns: int = 1_200_000,\n",
    "            plausible_ops = (\"Conv2D\",\"FC\",\"ReLU\",\"MaxPool\",\"Softmax\",\"BiasAdd\")) -> List[Tuple[int,str]]:\n",
    "    # recompute hit via latency\n",
    "    rows = []\n",
    "    for ts, f, lat, is_hit in records:\n",
    "        hit = is_hit or (lat < latency_hit_threshold)\n",
    "        if hit:\n",
    "            rows.append((ts, f))\n",
    "    # per-function debounce\n",
    "    rows.sort(key=lambda x: (x[1], x[0]))\n",
    "    kept = []\n",
    "    last_t = {}\n",
    "    for ts, f in rows:\n",
    "        lt = last_t.get(f, -10**18)\n",
    "        if ts - lt >= per_func_debounce_ns:\n",
    "            kept.append((ts,f))\n",
    "            last_t[f] = ts\n",
    "    kept.sort(key=lambda x: x[0])\n",
    "    # plausibility filter for VGG\n",
    "    kept = [r for r in kept if r[1] in plausible_ops]\n",
    "    return kept\n",
    "\n",
    "def vgg_fsm_parse(events: List[Tuple[int,str]], convs_per_block: List[int]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Grammar:\n",
    "      For each block b with k=convs_per_block[b]:\n",
    "        repeat k times: Conv2D -> [BiasAdd]? -> ReLU\n",
    "        then: MaxPool\n",
    "      Classifier:\n",
    "        (FC -> [BiasAdd]? -> ReLU) x2\n",
    "        (FC -> [BiasAdd]? -> Softmax) x1\n",
    "    \"\"\"\n",
    "    recovered = []\n",
    "    state = \"BLOCKS\"\n",
    "    b = 0\n",
    "    c_in_block = 0\n",
    "    need_relu = False\n",
    "    bias_seen = False\n",
    "    fc_count = 0\n",
    "    expect_relu = False\n",
    "    bias_seen_fc = False\n",
    "    for ts, f in events:\n",
    "        if state == \"BLOCKS\":\n",
    "            if b < len(convs_per_block):\n",
    "                k = convs_per_block[b]\n",
    "                if f == \"Conv2D\" and not need_relu and c_in_block < k:\n",
    "                    recovered.append(\"Conv2D\")\n",
    "                    need_relu = True\n",
    "                    bias_seen = False\n",
    "                elif f == \"BiasAdd\" and need_relu and not bias_seen:\n",
    "                    recovered.append(\"BiasAdd\")\n",
    "                    bias_seen = True\n",
    "                elif f == \"ReLU\" and need_relu:\n",
    "                    recovered.append(\"ReLU\")\n",
    "                    need_relu = False\n",
    "                    c_in_block += 1\n",
    "                elif f == \"MaxPool\" and (c_in_block == k) and not need_relu:\n",
    "                    recovered.append(\"MaxPool\")\n",
    "                    b += 1; c_in_block = 0\n",
    "            if b == len(convs_per_block) and not need_relu:\n",
    "                state = \"CLS\"\n",
    "        elif state == \"CLS\":\n",
    "            # three FC groups\n",
    "            if f == \"FC\" and not expect_relu and fc_count < 3:\n",
    "                recovered.append(\"FC\")\n",
    "                fc_count += 1\n",
    "                expect_relu = True\n",
    "                bias_seen_fc = False\n",
    "            elif f == \"BiasAdd\" and expect_relu and not bias_seen_fc:\n",
    "                recovered.append(\"BiasAdd\")\n",
    "                bias_seen_fc = True\n",
    "            elif f in (\"ReLU\",\"Softmax\") and expect_relu:\n",
    "                want = \"ReLU\" if fc_count < 3 else \"Softmax\"\n",
    "                if f == want:\n",
    "                    recovered.append(f)\n",
    "                    expect_relu = False\n",
    "                # stop after Softmax accepted\n",
    "                if fc_count == 3 and f == \"Softmax\":\n",
    "                    break\n",
    "    return recovered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042c39ec",
   "metadata": {},
   "source": [
    "# 4) Main\n",
    "\n",
    "Compare GT vs Recovered attributes in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a445e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    set_seed(7)\n",
    "\n",
    "    # Build model and get GT op sequence via hooks\n",
    "    model = VGG16WithSoftmax()\n",
    "    x = torch.randint(0, 256, (1, 3, 224, 224), dtype=torch.uint8).float()\n",
    "    gt_ops = record_ops(model, x)\n",
    "\n",
    "    # Expected VGG16 convs per block (derive from GT by pooling split for robustness)\n",
    "    gt_blocks = split_blocks_no_bias(gt_ops)\n",
    "    convs_per_block = [sum(1 for op in b if op==\"Conv2D\") for b in gt_blocks]\n",
    "    # Fallback to canonical if something odd happens\n",
    "    if convs_per_block != [2,2,3,3,3]:\n",
    "        convs_per_block = [2,2,3,3,3]\n",
    "\n",
    "    # Op durations (µs) — rough realism\n",
    "    durations_us = {\n",
    "        \"Conv2D\": 2200, \"FC\": 1000, \"ReLU\": 120, \"MaxPool\": 160,\n",
    "        \"AvgPool\": 160, \"Softmax\": 120, \"Merge\": 140, \"BiasAdd\": 90\n",
    "    }\n",
    "\n",
    "    # Simulate probe trace with noise\n",
    "    records = simulate_trace(\n",
    "        gt_seq=gt_ops,\n",
    "        durations_us=durations_us,\n",
    "        probe_interval_us=40,\n",
    "        hit_prob_active=0.98,\n",
    "        false_pos_rate=0.002,\n",
    "        drop_rate=0.01\n",
    "    )\n",
    "\n",
    "    # Denoise → chronological events\n",
    "    events = denoise(records,\n",
    "                     latency_hit_threshold=180,\n",
    "                     per_func_debounce_ns=1_200_000,\n",
    "                     plausible_ops=(\"Conv2D\",\"FC\",\"ReLU\",\"MaxPool\",\"Softmax\",\"BiasAdd\"))\n",
    "\n",
    "    # FSM parse to recover valid execution\n",
    "    recovered = vgg_fsm_parse(events, convs_per_block=convs_per_block)\n",
    "\n",
    "    # Attributes + blocks (ignore Bias for the block view)\n",
    "    gt_attrs = count_attrs(gt_ops)\n",
    "    rec_attrs = count_attrs(recovered)\n",
    "    rec_blocks = split_blocks_no_bias(recovered)\n",
    "    rec_convs_per_block = [sum(1 for op in b if op==\"Conv2D\") for b in rec_blocks]\n",
    "\n",
    "    # Pretty print\n",
    "    print(\"\\n=== Ground Truth (first 40 ops) ===\")\n",
    "    print(gt_ops[:40], \" ...\")\n",
    "    print(\"GT attributes:\", gt_attrs)\n",
    "    print(\"GT convs per block:\", convs_per_block)\n",
    "\n",
    "    print(\"\\n=== Recovered (first 40 ops) ===\")\n",
    "    print(recovered[:40], \" ...\")\n",
    "    print(\"Recovered attributes:\", rec_attrs)\n",
    "    print(\"Recovered convs per block:\", rec_convs_per_block)\n",
    "\n",
    "    # Simple quality metrics\n",
    "    def l1_attr_err(a,b):\n",
    "        keys = sorted(a.keys())\n",
    "        return sum(abs(a[k]-b.get(k,0)) for k in keys)\n",
    "    attr_err = l1_attr_err(gt_attrs, rec_attrs)\n",
    "    ok_blocks = (rec_convs_per_block == convs_per_block)\n",
    "    print(\"\\nL1 error over 8 attributes:\", attr_err)\n",
    "    print(\"Blocks match expected pattern [2,2,3,3,3]? ->\", ok_blocks)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
