# DeepRecon (VGG16) â€” Flush+Reload Simulation

This file contains a selfâ€‘contained **PyTorch** notebook that simulates a **Flush+Reloadâ€‘style sideâ€‘channel attack** to **recover the highâ€‘level architecture of VGG16**. It builds a canonical VGG16 model, logs a *groundâ€‘truth* operator sequence via forward hooks, **simulates noisy cacheâ€‘probe traces**, **denoises** them, and finally **parses** the events with a small **finiteâ€‘state machine (FSM)** tailored to VGG to reconstruct the network. It then compares **Recovered vs Groundâ€‘Truth** attributes.

> Notebook: `deeprecon.ipynb`

---

## What it does

1. **Build VGG16(+Softmax) & log ops** â€” A lightweight wrapper (`VGG16WithSoftmax`) around `torchvision.models.vgg16` adds a terminal Softmax and installs forward hooks to record the **groundâ€‘truth op sequence**.
2. **Simulate Flush+Reload probes** â€” `simulate_trace(...)` generates a **noisy probe trace** over frameworkâ€‘level ops with configurable timing, hit/miss latencies, drop/falseâ€‘positive rates, etc.
3. **Denoise the trace** â€” `denoise(...)` performs a **perâ€‘function debounce** and filters by a latency threshold to keep plausible events.
4. **FSM parsing for VGG** â€” `vgg_fsm_parse(...)` consumes denoised events and enforces a **VGG grammar** (Convâ†’[BiasAdd]?â†’ReLUâ†’â€¦â†’MaxPool; FC stages; final Softmax).
5. **Report metrics** â€” `count_attrs(...)` summarizes **8 attributes** (convs, fcs, relus, pools, softmaxes, biases, â€¦), block structure (**convs per block**), and shows **GT vs Recovered** (with an L1 error helper).

---

## ğŸ“ Files

- `deeprecon.ipynb` â€” The full simulation, utilities, and analysis.

---

## Requirements

- Python 3.9+
- PyTorch and TorchVision
- NumPy

Install (CPUâ€‘only example):

```bash
pip install numpy torch torchvision
```

For CUDA builds, see the official PyTorch installation selector.

---

## How to run

1. **Clone your repo** and open the notebook:
   ```bash
   git clone <your-repo-url>.git
   cd <your-repo>
   jupyter notebook deeprecon.ipynb
   ```
2. **Run topâ€‘toâ€‘bottom**. The notebook:
   - Builds VGG16 and logs a GT op sequence via hooks.
   - Simulates a probe trace with noise.
   - Denoises and FSMâ€‘parses events.
   - Prints a **Recovered vs GT** comparison table and block structure (expected VGG16: `[2, 2, 3, 3, 3]` convs per block).
3. **Tweak noise/latencies** in `simulate_trace(...)` to stress the pipeline.

---

## How it works (high level)

- **Ground truth logging:** Forward hooks map modules to coarse op names (`Conv2D`, `ReLU`, `MaxPool`, `FC`, `BiasAdd`, `Softmax`).  
- **Probe simulation:** A scheduled list of op windows is probed at a fixed interval, emitting **hit/miss latencies** with userâ€‘set probabilities and jitter.  
- **Denoising:** Converts latencies â†’ hits, applies **perâ€‘function debounce** and plausibility filtering.  
- **FSM parsing:** A tiny **VGG FSM** parses the event stream to a **valid architecture sequence**, discarding outâ€‘ofâ€‘grammar noise.  
- **Comparison:** Attribute counts and block structure are compared against GT; a small helper reports **L1 errors** per attribute.

---

## Expected output

- A printed table with **GT vs Recovered** for the 8 attributes.  
- **Convs per block** vector close to **`[2, 2, 3, 3, 3]`**.  
- Example artifacts: first 30 GT ops, latency histogram (hits vs misses), event counts before/after denoising.

> Stochastic components (seeds, noise) may cause small runâ€‘toâ€‘run differences; set `set_seed(7)` for reproducibility.

---

## Key functions & classes

- `VGG16WithSoftmax(nn.Module)` â€” wraps `torchvision.models.vgg16` and appends Softmax.  
- `record_ops(model, x)` â€” registers hooks and returns the **GT op sequence**.  
- `simulate_trace(gt_seq, durations_us, ...)` â€” generates probe records with **hit/miss latencies**.  
- `denoise(records, ...)` â€” thresholds latencies + perâ€‘function debounce â†’ chronological events.  
- `vgg_fsm_parse(events, convs_per_block)` â€” parses events under the **VGG grammar**.  
- `count_attrs(seq)` â€” returns the 8â€‘attribute summary.  
- `main()` â€” endâ€‘toâ€‘end run and report.
